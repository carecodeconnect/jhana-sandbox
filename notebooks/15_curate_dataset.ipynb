{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform `.txt` guided-meditation-collection to `.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conversion to JSONL completed.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Path to the directory containing .txt files\n",
    "input_dir = '../data/input/text/guided-meditation-collection/cleaned-txt'\n",
    "output_path = '../data/input/text/guided-meditation-collection/jhana-guided-meditation-collection.jsonl'\n",
    "\n",
    "# Sample instructions for meditation guidance\n",
    "instructions_examples = [\n",
    "    \"Guide me through a meditation to cultivate feelings of love and compassion\",\n",
    "    \"Lead a loving kindness practice\",\n",
    "    \"Assist me in a meditation for cultivating compassion towards others\",\n",
    "    \"Help cultivate warm-heartedness\",\n",
    "    \"Guide a meditation for feeling connected and open-hearted\",\n",
    "    \"Facilitate heart-felt meditation\",\n",
    "    \"Meditation guidance for loving-kindness towards self and others\",\n",
    "    \"Compassion practice guidance\",\n",
    "    \"Meditation for cultivating goodness and peace\",\n",
    "    \"Assist in developing friendliness through meditation\",\n",
    "    \"Guide a gratitude and positivity meditation\",\n",
    "    \"Teach a metta meditation\",\n",
    "    \"Loving-kindness and compassion meditation guidance\",\n",
    "    \"Concentration and sensory experience meditation on Vedana\",\n",
    "    \"Vedana meditation guide\",\n",
    "    \"Assist in feeling emotions through meditation\",\n",
    "    \"Loving kindness meditation facilitation\"\n",
    "]\n",
    "\n",
    "def create_jsonl_object(system, instruction, output):\n",
    "    return {\n",
    "        \"system\": system,\n",
    "        \"instruction\": instruction,\n",
    "        \"output\": output.lstrip()  # Remove leading spaces\n",
    "    }\n",
    "\n",
    "def transform_silence(text):\n",
    "    # Convert \"silence: 59.0\" to \"[59.0]\" without adding new lines\n",
    "    return re.sub(r'silence: (\\d+\\.\\d+)', r'[\\1]', text)\n",
    "\n",
    "def convert_txt_to_jsonl(input_dir, output_path):\n",
    "    if not os.path.isdir(input_dir):\n",
    "        return \"Input directory does not exist.\"\n",
    "\n",
    "    jsonl_objects = []\n",
    "    for file_name in filter(lambda f: f.endswith('.txt'), os.listdir(input_dir)):\n",
    "        with open(os.path.join(input_dir, file_name), 'r') as file:\n",
    "            content = transform_silence(file.read())\n",
    "\n",
    "        jsonl_object = create_jsonl_object(\n",
    "            system=\"Guidance as a meditation assistant for Jhana meditation\",\n",
    "            instruction=random.choice(instructions_examples),\n",
    "            output=content\n",
    "        )\n",
    "        jsonl_objects.append(jsonl_object)\n",
    "\n",
    "    with open(output_path, 'w') as output_file:\n",
    "        for obj in jsonl_objects:\n",
    "            output_file.write(json.dumps(obj) + '\\n')\n",
    "\n",
    "    return \"Conversion to JSONL completed.\"\n",
    "\n",
    "# Execute the conversion process\n",
    "convert_txt_to_jsonl(input_dir, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conversion to JSONL completed.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Path to the directory containing .txt files\n",
    "input_dir = '../data/input/text/guided-meditation-collection/cleaned-txt'\n",
    "output_path = '../data/input/text/guided-meditation-collection/jhana-guided-meditation-collection.jsonl'\n",
    "\n",
    "# Sample instructions for meditation guidance\n",
    "instructions_examples = [\n",
    "    \"Guide me through a meditation to cultivate feelings of love and compassion\",\n",
    "    \"Lead a loving kindness practice\",\n",
    "    \"Assist me in a meditation for cultivating compassion towards others\",\n",
    "    \"Help cultivate warm-heartedness\",\n",
    "    \"Guide a meditation for feeling connected and open-hearted\",\n",
    "    \"Facilitate heart-felt meditation\",\n",
    "    \"Meditation guidance for loving-kindness towards self and others\",\n",
    "    \"Compassion practice guidance\",\n",
    "    \"Meditation for cultivating goodness and peace\",\n",
    "    \"Assist in developing friendliness through meditation\",\n",
    "    \"Guide a gratitude and positivity meditation\",\n",
    "    \"Teach a metta meditation\",\n",
    "    \"Loving-kindness and compassion meditation guidance\",\n",
    "    \"Assist in feeling emotions through meditation\",\n",
    "    \"Loving kindness meditation facilitation\"\n",
    "]\n",
    "\n",
    "def create_jsonl_object(system, instruction, output):\n",
    "    return {\n",
    "        \"system\": system,\n",
    "        \"instruction\": instruction,\n",
    "        \"output\": output.lstrip()  # Remove leading spaces\n",
    "    }\n",
    "\n",
    "def apply_replacements(text):\n",
    "    replacements = {\n",
    "        \"Dhammas\": \"jhanas\",\n",
    "        \"10th\": \"tense\",\n",
    "        \"worms\": \"warmth\",\n",
    "        \"Worms\": \"warmth\",\n",
    "        \"Philip Worms\": \"feel the warmth\",\n",
    "        \"Mittha\": \"metta\",\n",
    "        \"metha\": \"metta\",\n",
    "        \"no order to\": \"now in order to\",\n",
    "        \"North America\": \"the world\",\n",
    "        \"at Oakwood\": \"at this place\",\n",
    "        # Corrections for 'jhana'\n",
    "        \"jhāna\": \"jhana\", \"chana\": \"jhana\", \"jnana\": \"jhana\",\n",
    "        \"jhanah\": \"jhana\", \"jhan\": \"jhana\", \"jharnas\": \"jhanas\", \"janas\": \"jhanas\",\n",
    "        \"jauna\": \"jhana\", \"janna\": \"jhana\", \"janam\": \"jhana\", \"jana\": \"jhana\",\n",
    "        \"jaina\": \"jhana\", \"shana\": \"jhana\", \"Chana\": \"jhana\", \"Jhanas\": \"jhanas\",\n",
    "        \"Jnana\": \"jhana\", \"Jhanah\": \"jhana\", \"Jhan\": \"jhana\", \"Jharnas\": \"jhanas\",\n",
    "        \"Janas\": \"jhanas\", \"Jauna\": \"jhana\", \"Janna\": \"jhana\", \"Janam\": \"jhana\",\n",
    "        \"Jana\": \"jhana\", \"Jaina\": \"jhana\", \"Shana\": \"jhana\",\n",
    "        \"Janus\": \"jhanas\", \"janus\": \"jhanas\",\n",
    "        \"Jhanus\": \"jhanas\", \"jhanus\": \"jhanas\",\n",
    "        \"jnanas\": \"jhanas\", \"Jnanas\": \"jhanas\",\n",
    "        \"jāna\": \"jhana\", \"Jāna\": \"jhana\", \"jānas\": \"jhanas\", \"Jānas\": \"jhanas\",\n",
    "        \"jama\": \"jhana\", \"Jama\": \"jhana\", \"jamas\": \"jhanas\", \"Jamas\": \"jhanas\",\n",
    "        \"johnna\": \"jhana\", \"Johnna\": \"jhana\", \n",
    "        \"jhani\": \"jhana\", \"Jhani\": \"jhana\", \"jhanis\": \"jhanas\", \"Jhanis\": \"jhanas\",\n",
    "        \"vipassanjana\": \"vipassanajhana\", \"Vipassanjana\": \"vipassanajhana\",\n",
    "        \"vaginas\": \"jhanas\", \"Vaginas\": \"jhanas\",\n",
    "        \"vagina\": \"jhana\",\n",
    "        \"vaginal\": \"jhana\",\n",
    "        # Corrections for 'jhanic'\n",
    "        \"jonic\": \"jhanic\", \"Jonic\": \"jhanic\",\n",
    "        \"jānic\": \"jhanic\", \"Jānic\": \"jhanic\",\n",
    "        # Corrections for 'jhanically'\n",
    "        \"jonically\": \"jhanically\", \"Jonically\": \"jhanically\",\n",
    "        # Corrections for 'sukkha'\n",
    "        \"sukha\": \"sukkha\", \"suka\": \"sukkha\", \"sukho\": \"sukkha\", \"sukhas\": \"sukkha\",\n",
    "        \"sukkha\": \"sukkha\", \"sukhara\": \"sukkha\", \"sukah\": \"sukkha\",\n",
    "        \"sukhi\": \"sukkha\", \"sukh\": \"sukkha\", \"sukkhas\": \"sukkha\", \"sukka\": \"sukkha\",\n",
    "        \"Suka\": \"sukkha\", \"suka\": \"sukkha\", \n",
    "        \"Sukho\": \"sukkha\", \"Sukhas\": \"sukkha\", \"Sukkha\": \"sukkha\",\n",
    "        \"Sukhara\": \"sukkha\", \"Sukah\": \"sukkha\", \"Sukhi\": \"sukkha\", \"Sukh\": \"sukkha\",\n",
    "        \"Sukkhas\": \"sukkha\", \"Sukka\": \"sukkha\", \"Sukha\": \"sukkha\",\n",
    "        \"SUCA\": \"sukkha\", \"suca\": \"sukkha\", \"Suca\": \"sukkha\", \"sukkah\": \"sukkha\", \"Sukkah\": \"sukkha\",\n",
    "        \"sukkah\": \"sukkha\", \"Sukkah\": \"sukkha\",\n",
    "        \"suko\": \"sukkha\", \"Suko\": \"sukkha\",\n",
    "        \"suga\": \"sukkha\", \"Suga\": \"sukkha\",\n",
    "        \"sookah\": \"sukkha\", \"Sookah\": \"sukkha\",\n",
    "        \"Sookha\": \"sukkha\", \"Sook-ka\": \"sukkha\",\n",
    "        \"sook\": \"sukkha\", \"Sook\": \"sukkha\",\n",
    "        \"tsuka\": \"sukkha\", \"Tsuka\": \"sukkha\",\n",
    "        # Corrections for 'dukkha'\n",
    "        \"duhka\": \"dukkha\", \"Duhka\": \"dukkha\", \"duhkas\": \"dukkhas\", \"Duhkas\": \"dukkhas\",\n",
    "        \"dukha\": \"dukkha\", \"Dukha\": \"dukkha\", \"duhkas\": \"dukkhas\", \"Dukhas\": \"dukkhas\",\n",
    "        # Corrections for 'piti'\n",
    "        \"pithi\": \"piti\", \"Pithi\": \"piti\", \"pitti\": \"piti\", \"Pitti\": \"piti\",\n",
    "        \"PT\": \"piti\", \"Pity\": \"piti\", \"pitya\": \"piti\", \"Pitya\": \"piti\",\n",
    "        \"pity\": \"piti\", \"Pity\": \"piti\", \"pete\": \"piti\", \"Pete\": \"piti\",\n",
    "        \" Pt \": \" piti \", \" pt \": \" piti \",\n",
    "        \"Pt\": \"piti\", \"pt\": \"piti\",\n",
    "        \"pd\": \"piti\", \"Pd\": \"piti\",\n",
    "        \"PD\": \"piti\",\n",
    "        \"pti\": \"piti\", \"Pti\": \"piti\",\n",
    "        \"pitta\": \"piti\", \"Pitta\": \"piti\",\n",
    "        \"ptsuka\": \"piti-sukkha\",\n",
    "        # Corrections for 'samatha'\n",
    "        \"shamata\": \"samatha\", \"shamatha\": \"samatha\", \"Shamata\": \"samatha\", \"Shamatha\": \"samatha\",\n",
    "        # Corrections for 'vitakka'\n",
    "        \"vitaka\": \"vitakka\", \"Vitaka\": \"vitakka\", \"vittaka\": \"vitakka\", \"Vittaka\": \"vitakka\",\n",
    "        \"vidakka\": \"vitakka\", \"Vidakka\": \"vitakka\",\n",
    "        \"vittakka\": \"vitakka\", \"Vittakka\": \"vitakka\",\n",
    "        \"vataka\": \"vitakka\", \"Vataka\": \"vitakka\",\n",
    "        \"vittacca\": \"vitakka\", \"Vittacca\": \"vitakka\",\n",
    "        \"vittak\": \"vitakka\", \"Vittak\": \"vitakka\",\n",
    "        \"vittakka\": \"vitakka\", \"Vittakka\": \"vitakka\",\n",
    "        # Corrections for 'vichara':\n",
    "        \"vichar\": \"vichara\", \"Vichar\": \"vichara\",\n",
    "        # Corrections for 'metta'\n",
    "        \"metha\": \"metta\", \"Metha\": \"metta\", \"meta\": \"metta\", \"Meta\": \"metta\",\n",
    "        # Corrections for 'Visuddhimagga'\n",
    "        \"Vasuti Maga\": \"Visuddhimagga\", \"Vasude maga\": \"Visuddhimagga\", \"Vasudhimagra\": \"Visuddhimagga\",\n",
    "        \"Visuddhimagra\": \"Vissuddhimagga\", \"Visuddhimaga\": \"Visuddhimagga\",\n",
    "        \"vesuddhimaga\": \"Visuddhimagga\", \"Vesuddhimaga\": \"Visuddhimagga\",\n",
    "        \"vishuddhimag\": \"Visuddhimagga\", \"Vishuddhimag\": \"Visuddhimagga\",\n",
    "        \"vishuddhimag\": \"Visuddhimagga\", \"Vishuddhimag\": \"Visuddhimagga\",\n",
    "        \"Visiddhi Maga\": \"Visuddhimagga\", \"Visiddhi Magga\": \"Visuddhimagga\",\n",
    "        \"Vasude Maga\": \"Visuddhimagga\", \"Vasude maga\": \"Visuddhimagga\",\n",
    "        \"Visiddhi Maga\": \"Visuddhimagga\",\n",
    "        # Corrections for 'Nimitta'\n",
    "        \"nimuta\": \"nimitta\", \"Nimuta\": \"nimitta\",\n",
    "        # Corrections for 'Kalapa'\n",
    "        \"kalabhas\": \"kalapas\", \"kalabha\": \"kalapa\", \"kalabhas\": \"kalapas\", \"kalabha\": \"kalapa\",\n",
    "        # Corrections for 'Ekaggata'\n",
    "        \"ikagata\": \"ekaggata\", \"ikaggata\": \"ekaggata\",\n",
    "        \"kagata\": \"ekaggata\", \"kagata\": \"ekaggata\", \"Kagata\": \"ekaggata\",\n",
    "        \"ekaggata\": \"ekaggata\", \"Ekaggata\": \"ekaggata\",\n",
    "        \"ekagata\": \"ekaggata\", \"Ekagata\": \"ekaggata\",\n",
    "        \"ekakata\": \"ekaggata\", \"Ekakata\": \"ekaggata\",\n",
    "        \"akagata\": \"ekaggata\", \"Akagata\": \"ekaggata\",\n",
    "        # Corrections for 'Vipassana'\n",
    "        \"viparsana\": \"vipassana\", \"vipasana\": \"vipassana\",\n",
    "        \"Viparsana\": \"vipassana\", \"Vipasana\": \"vipassana\",\n",
    "        # Corrections for 'anicca'\n",
    "        \"anicya\": \"anicca\", \"Anicya\": \"anicca\",\n",
    "        \"anicha\": \"anicca\", \"Anicha\": \"anicca\",\n",
    "        # Corrections for 'Upekkha'\n",
    "        \"Upekha\": \"upekkha\", \"upekha\": \"upekkha\",\n",
    "        \"Upeka\": \"upekkha\", \"upeka\": \"upekkha\",\n",
    "        # Corrections for 'drenches'\n",
    "        \"dringes\": \"drenches\",\n",
    "        # Corrections for 'hindrances'\n",
    "        \"hindrins\": \"hindrances\",\n",
    "        # Corrections for 'panna'\n",
    "        \"panya\": \"panna\",\n",
    "        \"Panya\": \"panna\",\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        text = text.replace(old, new)\n",
    "    return text\n",
    "\n",
    "def transform_silence(text):\n",
    "    # Apply replacements, remove newline characters, and transform \"silence\" notation\n",
    "    text = apply_replacements(text)\n",
    "    text_no_silence = re.sub(r'silence: (\\d+\\.\\d+)', r'[\\1]', text)\n",
    "    return text_no_silence.replace('\\n', '')\n",
    "\n",
    "def convert_txt_to_jsonl(input_dir, output_path):\n",
    "    if not os.path.isdir(input_dir):\n",
    "        return \"Input directory does not exist.\"\n",
    "\n",
    "    jsonl_objects = []\n",
    "    for file_name in filter(lambda f: f.endswith('.txt'), os.listdir(input_dir)):\n",
    "        with open(os.path.join(input_dir, file_name), 'r') as file:\n",
    "            content = transform_silence(file.read())\n",
    "\n",
    "        jsonl_object = create_jsonl_object(\n",
    "            system=\"You are a meditation assistant who guides the user through a Jhana meditation\",\n",
    "            instruction=random.choice(instructions_examples),\n",
    "            output=content\n",
    "        )\n",
    "        jsonl_objects.append(jsonl_object)\n",
    "\n",
    "    with open(output_path, 'w') as output_file:\n",
    "        for obj in jsonl_objects:\n",
    "            output_file.write(json.dumps(obj) + '\\n')\n",
    "\n",
    "    return \"Conversion to JSONL completed.\"\n",
    "\n",
    "# Execute the conversion process\n",
    "convert_txt_to_jsonl(input_dir, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This created a 75-row JSONL file from a guided-meditation-collection text file. Each row is a JSON object.\n",
    "\n",
    "Then, I gave this prompt to GPT-4, to increase the dataset size:\n",
    "\n",
    "```\n",
    "read the following JSONL file. create an additional 10 examples in JSONL format. keep the \"system\" values the same.  vary the \"instruction\" based on these examples, which should match with the \"output\".  the \"output\" of the new examples should be very similar to the following examples. create some slightly different - but mostly similar - examples. include pauses, as in these examples: \n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhana_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
